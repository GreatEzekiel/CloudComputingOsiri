{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparative Analysis of Eighteen Machine Learning Models for Stock Price Forecasting in the Financial Sector Using Historical Yahoo Finance Data.**"
      ],
      "metadata": {
        "id": "-ivucecQ2wQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aim and Objectives of the Study\n",
        "\n",
        "The general objective of this study is to conduct a comprehensive comparative analysis of eighteen machine learning models for stock price forecasting in the financial sector using historical Yahoo Finance data. The specific objectives of the study are to:\n",
        "\n",
        "- Examine the predictive performance of traditional regression-based machine learning models in forecasting stock prices.\n",
        "\n",
        "- Evaluate the effectiveness of tree-based and ensemble learning models for financial time-series prediction.\n",
        "\n",
        "- Assess the capability of kernel-based and probabilistic models in capturing non-linear stock price dynamics.\n",
        "\n",
        "- Analyze the forecasting accuracy of deep learning models in comparison with conventional machine learning techniques."
      ],
      "metadata": {
        "id": "2ZhHzcMudUpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Library Importation**"
      ],
      "metadata": {
        "id": "kccpPWF2Es5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "ZApBkJPm35YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading**"
      ],
      "metadata": {
        "id": "BFj5slDE5AI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "p3iZGLXd5E3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('yahooStock.csv')"
      ],
      "metadata": {
        "id": "wwFYNEVU_KpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "FLwy37Pn5bJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "wUdDYWjn2PdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering: Clean 'transactionType' column\n",
        "df_processed = df.copy()\n",
        "df_processed['transactionType_cleaned'] = df_processed['transactionType'].astype(str).str.strip().str.upper()\n",
        "\n",
        "# Debugging: Check unique cleaned transaction types before filtering\n",
        "print(\"Unique cleaned transaction types found in the dataset:\")\n",
        "print(df_processed['transactionType_cleaned'].unique())\n",
        "print(\"Value counts for cleaned transaction types:\")\n",
        "print(df_processed['transactionType_cleaned'].value_counts())"
      ],
      "metadata": {
        "id": "SLLT3yP52Y9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf248cdb"
      },
      "source": [
        "# Filter for relevant transaction types ('BUY' or 'SELL')\n",
        "purchase_mask = df_processed['transactionType_cleaned'].str.contains('BUY', na=False)\n",
        "sale_mask = df_processed['transactionType_cleaned'].str.contains('SELL', na=False)\n",
        "\n",
        "# Combine masks for filtering\n",
        "df_filtered = df_processed[purchase_mask | sale_mask].copy()\n",
        "\n",
        "# Create 'Target' column: 1 for Purchase (BUY), 0 for Sale (SELL)\n",
        "df_filtered['Target'] = np.where(df_filtered['transactionType_cleaned'].str.contains('BUY', na=False), 1, 0)\n",
        "\n",
        "print(\"DataFrame filtered for 'BUY' and 'SELL' transactions, and 'Target' column created.\")\n",
        "print(\"Head of df_filtered:\\n\", df_filtered.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9f2d012"
      },
      "source": [
        "# Select features from available numerical columns and handle potential NaNs\n",
        "numerical_features = ['amount', 'reportedPrice', 'usdValue']\n",
        "for col in numerical_features:\n",
        "    df_filtered[col] = pd.to_numeric(df_filtered[col], errors='coerce')\n",
        "\n",
        "# Drop rows with NaN values only in the selected features or target\n",
        "df_final = df_filtered.dropna(subset=numerical_features + ['Target'])\n",
        "\n",
        "X = df_final[numerical_features]\n",
        "y = df_final['Target']\n",
        "\n",
        "# Check if X is empty after all processing steps\n",
        "if X.empty:\n",
        "    raise ValueError(\"DataFrame is empty after filtering and NaN removal. No data to train on. Check 'transactionType' values and numerical features.\")\n",
        "\n",
        "# Print target class distribution before train-test split\n",
        "print(\"\\nTarget class distribution before train-test split:\")\n",
        "print(y.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "HIQPS8rp1wKP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aaf4984"
      },
      "source": [
        "### **Visualize 'amount' with a Box Plot**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bcf9e45"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Target', y='amount', data=df_final)\n",
        "plt.title('Distribution of Transaction Amount by Target')\n",
        "plt.xlabel('Target (0: SELL, 1: BUY)')\n",
        "plt.ylabel('Amount')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46610548"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(x='Target', y='reportedPrice', data=df_final)\n",
        "plt.title('Distribution of Reported Price by Target')\n",
        "plt.xlabel('Target (0: SELL, 1: BUY)')\n",
        "plt.ylabel('Reported Price')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0eb4871"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "sns.scatterplot(x='amount', y='usdValue', hue='Target', data=df_final, palette='viridis', alpha=0.7)\n",
        "plt.title('Relationship between Amount and USD Value by Target')\n",
        "plt.xlabel('Amount')\n",
        "plt.ylabel('USD Value')\n",
        "plt.legend(title='Target (0: SELL, 1: BUY)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffe37365"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_final['eodHolding'], bins=50, kde=True)\n",
        "plt.title('Distribution of End of Day Holding')\n",
        "plt.xlabel('End of Day Holding')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34f85bb9"
      },
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='symbolType', data=df_final)\n",
        "plt.title('Distribution of Symbol Type')\n",
        "plt.xlabel('Symbol Type')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a16ff632"
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "df_final['hasOptions'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=sns.color_palette('pastel'))\n",
        "plt.title('Distribution of Has Options')\n",
        "plt.ylabel('') # Hide the default y-label\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "683eda05"
      },
      "source": [
        "### **Transaction Type distribution across Symbol Types**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a5d1a93"
      },
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "sns.countplot(x='symbolType', hue='Target', data=df_final, palette='viridis')\n",
        "plt.title('Transaction Type Distribution Across Symbol Types')\n",
        "plt.xlabel('Symbol Type')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Target (0: SELL, 1: BUY)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aff82eb"
      },
      "source": [
        "### **Transaction Type distribution by Has Options**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "335b7193"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='hasOptions', hue='Target', data=df_final, palette='viridis')\n",
        "plt.title('Transaction Type Distribution by Has Options')\n",
        "plt.xlabel('Has Options')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Target (0: SELL, 1: BUY)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f129f9f0"
      },
      "source": [
        "### **Average Amount by Symbol Type**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cfd1a59"
      },
      "source": [
        "# Calculate the average 'amount' for each 'symbolType'\n",
        "average_amount_by_symbol_type = df_final.groupby('symbolType')['amount'].mean().reset_index()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='symbolType', y='amount', hue='symbolType', data=average_amount_by_symbol_type, palette='viridis', legend=False)\n",
        "plt.title('Average Transaction Amount by Symbol Type')\n",
        "plt.xlabel('Symbol Type')\n",
        "plt.ylabel('Average Amount')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a928c87"
      },
      "source": [
        "### **Average Amount by Has Options**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82bcb6ce"
      },
      "source": [
        "plt.figure(figsize=(7, 5))\n",
        "sns.countplot(x='hasOptions', data=df_final, palette='viridis', hue='hasOptions', legend=False)\n",
        "plt.title('Distribution of Has Options')\n",
        "plt.xlabel('Has Options')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397f03fe"
      },
      "source": [
        "### **Distribution of 'symbolCode'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "713a7f4a"
      },
      "source": [
        "plt.figure(figsize=(7, 5))\n",
        "sns.countplot(x='symbolCode', data=df_final, palette='viridis', hue='symbolCode', legend=False)\n",
        "plt.title('Distribution of Symbol Code')\n",
        "plt.xlabel('Symbol Code')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pair Plot of Numerical Features and Target**"
      ],
      "metadata": {
        "id": "ms4MPDtgEFv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n### Pair Plot of Numerical Features and Target:\\n\")\n",
        "sns.pairplot(df_final[numerical_features + ['Target']], hue='Target', diag_kind='kde')\n",
        "plt.suptitle('Pair Plot of Numerical Features by Target', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kQZGxgCR46R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Relationships Between Variables**"
      ],
      "metadata": {
        "id": "zXjD2KuPCjl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_final[numerical_features + ['Target']].corr())"
      ],
      "metadata": {
        "id": "iYUm_MafDIy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n### Correlation Matrix:\\n\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df_final[numerical_features + ['Target']].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Numerical Features and Target')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "anIMl_pvFiLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Models**"
      ],
      "metadata": {
        "id": "eBRqVWPIHFj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train-test split**"
      ],
      "metadata": {
        "id": "Pr9G_RkdBxcY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8e9000e"
      },
      "source": [
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Data split into training and testing sets.\")\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Scaling**"
      ],
      "metadata": {
        "id": "cT6ot2u4B5cl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85134bf9"
      },
      "source": [
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "print(\"Features scaled using StandardScaler.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Handle imbalance (SMOTE) - only if there are at least two classes in y_train**"
      ],
      "metadata": {
        "id": "cjrKy0UbB-2w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e8f1942"
      },
      "source": [
        "# Handle imbalance (SMOTE) - only if there are at least two classes in y_train\n",
        "if len(np.unique(y_train)) > 1:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    x_train, y_train = smote.fit_resample(x_train, y_train)\n",
        "    print(\"SMOTE applied to x_train and y_train for imbalance handling.\")\n",
        "    print(f\"x_train shape after SMOTE: {x_train.shape}\")\n",
        "    print(f\"y_train shape after SMOTE: {y_train.shape}\")\n",
        "    print(\"Target class distribution after SMOTE:\")\n",
        "    print(pd.Series(y_train).value_counts())\n",
        "else:\n",
        "    print(\"Warning: SMOTE not applied. y_train contains only one class. Binary classification might be problematic.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Accuracy**"
      ],
      "metadata": {
        "id": "IAsA8XdESNtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_accuracy_at_k(y_true, y_pred_proba, k_percentages):\n",
        "    \"\"\"\n",
        "    Calculates Accuracy@k (precision at top k%) for given true labels and predicted probabilities.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): The actual labels (0 or 1).\n",
        "        y_pred_proba (array-like): The predicted probabilities for the positive class.\n",
        "        k_percentages (list): A list of float values representing the top k% thresholds (e.g., [0.10, 0.20, 0.30]).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are 'Accuracy@k%' (e.g., 'Accuracy@10%') and values are the calculated precision percentages.\n",
        "    \"\"\"\n",
        "    # 1. Combine y_true and y_pred_proba into a DataFrame\n",
        "    df_combined = pd.DataFrame({'true_label': y_true, 'predicted_proba': y_pred_proba})\n",
        "\n",
        "    # 2. Sort DataFrame by 'predicted_proba' in descending order\n",
        "    df_combined = df_combined.sort_values(by='predicted_proba', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # 3. Initialize dictionary to store results\n",
        "    accuracy_at_k_results = {}\n",
        "\n",
        "    # 4. Iterate through each k_percentage\n",
        "    for k_percentage in k_percentages:\n",
        "        # a. Calculate the number of samples for the current top k% threshold\n",
        "        k_count = int(len(y_true) * k_percentage)\n",
        "\n",
        "        # Handle the case where k_count is zero (e.g., k_percentage is very small or y_true is empty)\n",
        "        if k_count == 0:\n",
        "            accuracy_at_k_results[f'Accuracy@{int(k_percentage * 100)}%'] = 0.0\n",
        "            continue\n",
        "\n",
        "        # b. Select the top k_count samples from the sorted DataFrame\n",
        "        top_k_df = df_combined.head(k_count)\n",
        "\n",
        "        # c. Within these top k_count samples, count how many have a 'true_label' equal to 1\n",
        "        correct_predictions = top_k_df['true_label'].sum()\n",
        "\n",
        "        # d. Calculate the precision at k\n",
        "        precision_at_k = (correct_predictions / k_count) * 100\n",
        "\n",
        "        # e. Store this calculated precision (percentage) in the results dictionary\n",
        "        accuracy_at_k_results[f'Accuracy@{int(k_percentage * 100)}%'] = precision_at_k\n",
        "\n",
        "    return accuracy_at_k_results\n",
        "\n",
        "print(\"The 'calculate_accuracy_at_k' function has been defined.\")"
      ],
      "metadata": {
        "id": "oBdULSqEZEPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Linear & Probabilistic Models**"
      ],
      "metadata": {
        "id": "uPsxbDdtUG0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Linear Regression**"
      ],
      "metadata": {
        "id": "pKB-QrptUJNJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "921969a8"
      },
      "source": [
        "# Train Linear Regression\n",
        "# It treats y (0 or 1) as a continuous target\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(x_train, y_train)\n",
        "\n",
        "# Convert Continuous Output to Binary Class\n",
        "# We use 0.5 as the default threshold, but in imbalanced data,\n",
        "# you might lower this (e.g., 0.2) to increase Recall.\n",
        "raw_predictions = lr_model.predict(x_test)\n",
        "y_pred = (raw_predictions > 0.5).astype(int)\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_lr = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_lr)\n",
        "print(\"Accuracy percent of Linear Regression : \", round(train_score_lr*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", lr_model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nLinear Regression Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "lr_accuracy_at_k = calculate_accuracy_at_k(y_test, raw_predictions, [0.10, 0.20, 0.30])\n",
        "print(\"\\nLinear Regression Accuracy@k:\", lr_accuracy_at_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Logistic Regression (with SMOTE)**:"
      ],
      "metadata": {
        "id": "4DMfx8CeThFm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5ec0271"
      },
      "source": [
        "# Logic: Linear boundary with synthetic oversampling\n",
        "# SMOTE is already applied globally in the data preparation step (Ggj7iUq-IX7Z) on x_train and y_train.\n",
        "# So, directly use the resampled x_train, y_train for model training.\n",
        "model = LogisticRegression(max_iter=1000, random_state=42).fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_lr = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_lr)\n",
        "print(\"Accuracy percent of Logistic Regression : \", round(train_score_lr*100, 1), \"%\")\n",
        "print(\"Model score (on resampled train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "logistic_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nLogistic Regression Accuracy@k:\", logistic_accuracy_at_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221a7c70"
      },
      "source": [
        "### **3. Na誰ve Bayes**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8db35ee8"
      },
      "source": [
        "# Logic: Assumes independence between features\n",
        "model = GaussianNB().fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_nb = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_nb)\n",
        "print(\"Accuracy percent of Na誰ve Bayes : \", round(train_score_nb*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nNa誰ve Bayes Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "naive_bayes_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nNa誰ve Bayes Accuracy@k:\", naive_bayes_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "856bdc1a"
      },
      "source": [
        "### **4. LDA (Linear Discriminant Analysis)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f43e5750"
      },
      "source": [
        "# Logic: Maximizes class separability\n",
        "model = LinearDiscriminantAnalysis().fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_lda = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_lda)\n",
        "print(\"Accuracy percent of LDA : \", round(train_score_lda*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nLDA Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "lda_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nLDA Accuracy@k:\", lda_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Support Vector Machines (SVM)**"
      ],
      "metadata": {
        "id": "1F8l6DxQ-xAc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14526d01"
      },
      "source": [
        "# Logic: Finds the hyperplane that maximizes the margin between classes\n",
        "model = SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_svm = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_svm)\n",
        "print(\"Accuracy percent of SVM : \", round(train_score_svm*100, 1), \"%\")\n",
        "print(\"Model score (on resampled train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nSVM Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "svm_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nSVM Accuracy@k:\", svm_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "845fdc70"
      },
      "source": [
        "### **6. k-Nearest Neighbors (k-NN)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d76b6477"
      },
      "source": [
        "# Logic: Classifies based on local density\n",
        "# Apply TomekLinks for under-sampling (as per instruction for this cell)\n",
        "X_res_tl, y_res_tl = TomekLinks().fit_resample(x_train, y_train)\n",
        "\n",
        "# Initialize and fit k-NN model\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "model.fit(X_res_tl, y_res_tl)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_knn = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_knn)\n",
        "print(\"Accuracy percent of k-NN : \", round(train_score_knn*100, 1), \"%\")\n",
        "print(\"Model score (on resampled train data): \", model.score(X_res_tl, y_res_tl))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nk-NN Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "knn_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nk-NN Accuracy@k:\", knn_accuracy_at_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. t-SNE (t-Distributed Stochastic Neighbor Embedding)**\n",
        "\n",
        "A manifold learning technique for visualization and non-linear dimensionality reduction (similar to PCA, but better for identifying clusters in complex data)"
      ],
      "metadata": {
        "id": "qV31USNacKFt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "772fd12e"
      },
      "source": [
        "# Logic: Projects high-dimensional data into 2D or 3D while preserving local structure\n",
        "# Note: sklearn's TSNE does not have a 'transform' method for new data.\n",
        "# For demonstration purposes and to adhere to the template, we are applying\n",
        "# fit_transform separately to train and test data. This means the embedded\n",
        "# spaces are NOT guaranteed to be consistent, which is generally NOT ideal\n",
        "# for robust model evaluation on unseen test data.\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "X_train_embedded = tsne.fit_transform(x_train)\n",
        "\n",
        "# For prediction on x_test, we re-run fit_transform on x_test.\n",
        "# This creates an independent embedding for the test set.\n",
        "# A more robust approach for production would involve learning a mapping\n",
        "# from the original feature space to the embedded space.\n",
        "tsne_test = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "X_test_embedded = tsne_test.fit_transform(x_test)\n",
        "\n",
        "# Train Logistic Regression on the 2D embedded training coordinates\n",
        "model = LogisticRegression(random_state=42).fit(X_train_embedded, y_train)\n",
        "\n",
        "# Predict on the 2D embedded test coordinates\n",
        "y_pred = model.predict(X_test_embedded)\n",
        "y_pred_proba = model.predict_proba(X_test_embedded)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_tsne_lr = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_tsne_lr)\n",
        "print(\"Accuracy percent of t-SNE + LR : \", round(train_score_tsne_lr*100, 1), \"%\")\n",
        "print(\"Model score (on embedded train data): \", model.score(X_train_embedded, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nt-SNE + Logistic Regression Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "tsne_lr_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nt-SNE + Logistic Regression Accuracy@k:\", tsne_lr_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tree-Based Ensembles**"
      ],
      "metadata": {
        "id": "c-fwI2Vrb0Yk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45b35cfc"
      },
      "source": [
        "### **8. Decision Trees (Cost-Sensitive)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eb7d172"
      },
      "source": [
        "# Logic: Non-linear splits focusing on minority class weight\n",
        "model = DecisionTreeClassifier(class_weight='balanced', random_state=42).fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_dt = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_dt)\n",
        "print(\"Accuracy percent of Decision Tree : \", round(train_score_dt*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nDecision Tree Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "dt_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nDecision Tree Accuracy@k:\", dt_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f55ad7dd"
      },
      "source": [
        "### **9. Random Forest (Balanced)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5151f8c5"
      },
      "source": [
        "# Logic: Bagging with internal under-sampling\n",
        "rand_model = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rand_model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "pred2 = rand_model.predict(x_test)\n",
        "y_pred_proba = rand_model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_rand = metrics.accuracy_score(y_test, pred2)\n",
        "print('Accuracy score2 : ', train_score_rand)\n",
        "print(\"Accuracy percent of RFC : \", round(train_score_rand*100, 1), \"%\")\n",
        "print(\"Model score: \", rand_model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(metrics.classification_report(y_test, pred2))\n",
        "cm = metrics.confusion_matrix(y_test, pred2)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "rand_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nBalanced Random Forest Accuracy@k:\", rand_accuracy_at_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b936aae"
      },
      "source": [
        "### **10. Extra Trees (Extremely Randomized Trees)**\n",
        "\n",
        "Similar to Random Forest, but it chooses split points completely at random for each feature, which can further reduce variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8973293"
      },
      "source": [
        "# Logic: Randomized split points to reduce over-fitting on imbalanced noise\n",
        "model = ExtraTreesClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_et = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_et)\n",
        "print(\"Accuracy percent of Extra Trees : \", round(train_score_et*100, 1), \"%\")\n",
        "print(\"Model score (on resampled train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nExtra Trees Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "et_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nExtra Trees Accuracy@k:\", et_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ebbfedb"
      },
      "source": [
        "### **11. AdaBoost (Adaptive Boosting)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "846df5a4"
      },
      "source": [
        "# Logic: Weights misclassified instances more heavily\n",
        "X_res_adasyn, y_res_adasyn = ADASYN(random_state=42).fit_resample(x_train, y_train)\n",
        "model = AdaBoostClassifier(n_estimators=50, random_state=42).fit(X_res_adasyn, y_res_adasyn)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_ada = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_ada)\n",
        "print(\"Accuracy percent of AdaBoost : \", round(train_score_ada*100, 1), \"%\")\n",
        "print(\"Model score (on resampled train data): \", model.score(X_res_adasyn, y_res_adasyn))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nAdaBoost Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "ada_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nAdaBoost Accuracy@k:\", ada_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7994b040"
      },
      "source": [
        "### **12. Gradient Boosting (HistGradientBoosting)**\n",
        "\n",
        "Modern gradient boosting that handles missing values and large data well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "328c7194"
      },
      "source": [
        "# Logic: Sequential boosting focusing on previous errors\n",
        "model = HistGradientBoostingClassifier(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_gb = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_gb)\n",
        "print(\"Accuracy percent of Gradient Boosting : \", round(train_score_gb*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nGradient Boosting Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "gb_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nGradient Boosting Accuracy@k:\", gb_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbdd7078"
      },
      "source": [
        "\n",
        "### **13. XGBoost (Extreme Gradient Boosting)**\n",
        "\n",
        "Highly optimized distributed gradient boosting library.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43eb04ac"
      },
      "source": [
        "# Logic: Optimized Gradient Boosting with scale_pos_weight for imbalance\n",
        "# Calculate scale_pos_weight based on the current y_train distribution\n",
        "neg_count = np.sum(y_train == 0)\n",
        "pos_count = np.sum(y_train == 1)\n",
        "scale_pos_weight_value = neg_count / pos_count if pos_count > 0 else 1\n",
        "\n",
        "model = XGBClassifier(scale_pos_weight=scale_pos_weight_value, random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_xgb = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_xgb)\n",
        "print(\"Accuracy percent of XGBoost : \", round(train_score_xgb*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nXGBoost Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "xgb_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nXGBoost Accuracy@k:\", xgb_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "431a7d58"
      },
      "source": [
        "### **14. LightGBM (Light Gradient Boosting Machine)**\n",
        "\n",
        "A highly efficient framework that uses leaf-wise tree growth rather than level-wise growth, making it faster than standard XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce91248a"
      },
      "source": [
        "# Logic: Leaf-wise growth and Gradient-based One-Side Sampling (GOSS)\n",
        "model = LGBMClassifier(is_unbalance=True, random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_lgbm = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_lgbm)\n",
        "print(\"Accuracy percent of LightGBM : \", round(train_score_lgbm*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nLightGBM Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "lgbm_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nLightGBM Accuracy@k:\", lgbm_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23d5b79c"
      },
      "source": [
        "### **15. CatBoost (Categorical Boosting)**\n",
        "\n",
        "Developed by Yandex, this algorithm handles categorical features automatically and uses a \"symmetric tree\" structure to prevent prediction shift.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f55b0273"
      },
      "source": [
        "# Logic: Ordered boosting to solve the gradient bias problem\n",
        "model = CatBoostClassifier(auto_class_weights='Balanced', verbose=0, random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_cat = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_cat)\n",
        "print(\"Accuracy percent of CatBoost : \", round(train_score_cat*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nCatBoost Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "cat_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nCatBoost Accuracy@k:\", cat_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8cf84d9"
      },
      "source": [
        "## **Neural Networks & Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7da20f4b"
      },
      "source": [
        "### **16. Artificial Neural Networks (ANN - MLP)**\n",
        "\n",
        "Multi-layer Perceptron\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2afae6b"
      },
      "source": [
        "# Logic: Layered neurons with non-linear activation functions\n",
        "model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_ann = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_ann)\n",
        "print(\"Accuracy percent of ANN (MLP) : \", round(train_score_ann*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(x_train, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nANN (MLP) Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "ann_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nANN (MLP) Accuracy@k:\", ann_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0cd9749"
      },
      "source": [
        "### **17. Convolutional Neural Networks (CNN)**\n",
        "\n",
        "Requires data to be reshaped (typically for images or sequences)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b34fe676"
      },
      "source": [
        "# Reshape input data for Conv1D: (n_samples, n_features) -> (n_samples, timesteps, features)\n",
        "# Here, we treat each feature as a timestep, and the 'features' dimension is 1.\n",
        "n_samples_train, n_features_train = x_train.shape\n",
        "n_samples_test, n_features_test = x_test.shape\n",
        "\n",
        "x_train_reshaped = x_train.reshape(n_samples_train, n_features_train, 1)\n",
        "x_test_reshaped = x_test.reshape(n_samples_test, n_features_test, 1)\n",
        "\n",
        "# Define the Conv1D model\n",
        "model = models.Sequential([\n",
        "    layers.Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_features_train, 1)),\n",
        "    layers.MaxPooling1D(pool_size=1),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# Predict probabilities on test data\n",
        "y_pred_proba = model.predict(x_test_reshaped)\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_cnn = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_cnn)\n",
        "print(\"Accuracy percent of CNN : \", round(train_score_cnn*100, 1), \"%\")\n",
        "\n",
        "# Evaluate the model on the reshaped test data\n",
        "loss, accuracy = model.evaluate(x_test_reshaped, y_test, verbose=0)\n",
        "print(f\"Model Loss (on test data): {loss:.4f}\")\n",
        "print(f\"Model Accuracy (on test data): {accuracy:.4f}\")\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nCNN Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "cnn_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba.flatten(), [0.10, 0.20, 0.30])\n",
        "print(\"\\nCNN Accuracy@k:\", cnn_accuracy_at_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7ab067e"
      },
      "source": [
        "### **18. Recurrent Neural Networks (RNN/LSTM)**\n",
        "\n",
        "Best for sequential data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05b9ae36"
      },
      "source": [
        "# Reshape input data for LSTM: (n_samples, n_features) -> (n_samples, timesteps, features)\n",
        "# Here, we treat each feature as a timestep, and the 'features' dimension is 1.\n",
        "n_samples_train, n_features_train = x_train.shape\n",
        "n_samples_test, n_features_test = x_test.shape\n",
        "\n",
        "x_train_reshaped = x_train.reshape(n_samples_train, n_features_train, 1)\n",
        "x_test_reshaped = x_test.reshape(n_samples_test, n_features_test, 1)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = models.Sequential([\n",
        "    layers.LSTM(64, input_shape=(n_features_train, 1), activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# Predict probabilities on test data\n",
        "y_pred_proba = model.predict(x_test_reshaped)\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_lstm = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_lstm)\n",
        "print(\"Accuracy percent of RNN (LSTM) : \", round(train_score_lstm*100, 1), \"%\")\n",
        "\n",
        "# Evaluate the model on the reshaped test data\n",
        "loss, accuracy = model.evaluate(x_test_reshaped, y_test, verbose=0)\n",
        "print(f\"Model Loss (on test data): {loss:.4f}\")\n",
        "print(f\"Model Accuracy (on test data): {accuracy:.4f}\")\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nRNN (LSTM) Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "lstm_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba.flatten(), [0.10, 0.20, 0.30])\n",
        "print(\"\\nRNN (LSTM) Accuracy@k:\", lstm_accuracy_at_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a97cc1ad"
      },
      "source": [
        "### **19. Autoencoders (Unsupervised Feature Extraction)**\n",
        "\n",
        "Using a simple ANN structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac8d970e"
      },
      "source": [
        "# Logic: Learns a compressed representation (encoding) of the input\n",
        "# Define the autoencoder (MLPRegressor) to reconstruct its input\n",
        "# The hidden_layer_sizes define the encoded feature dimension (e.g., 2 for 2D visualization)\n",
        "autoencoder = MLPRegressor(hidden_layer_sizes=(2,), activation='relu', random_state=42, max_iter=500)\n",
        "autoencoder.fit(x_train, x_train)\n",
        "\n",
        "# Manually extract the activations of the first hidden layer for x_train and x_test\n",
        "# These are the encoded features\n",
        "def get_encoded_features(model, data):\n",
        "    # The output of the first layer is data @ coefs_[0] + intercepts_[0]\n",
        "    hidden_layer_output = data @ model.coefs_[0] + model.intercepts_[0]\n",
        "    # Apply the ReLU activation function, as specified in the MLPRegressor\n",
        "    return np.maximum(0, hidden_layer_output)\n",
        "\n",
        "X_train_encoded = get_encoded_features(autoencoder, x_train)\n",
        "X_test_encoded = get_encoded_features(autoencoder, x_test)\n",
        "\n",
        "# Train a Logistic Regression model on the encoded features\n",
        "model_lr_encoded = LogisticRegression(random_state=42)\n",
        "model_lr_encoded.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Predict on the encoded test data\n",
        "y_pred = model_lr_encoded.predict(X_test_encoded)\n",
        "y_pred_proba = model_lr_encoded.predict_proba(X_test_encoded)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_ae_lr = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_ae_lr)\n",
        "print(\"Accuracy percent of Autoencoder Features + LR : \", round(train_score_ae_lr*100, 1), \"%\")\n",
        "print(\"Model score (on encoded train data): \", model_lr_encoded.score(X_train_encoded, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nAutoencoder Features + LR Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "ae_lr_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nAutoencoder Features + LR Accuracy@k:\", ae_lr_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clustering & Unsupervised**"
      ],
      "metadata": {
        "id": "9C8dQHD7WXUf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dddc7308"
      },
      "source": [
        "### **20. k-Means Clustering**\n",
        "\n",
        "Unsupervised learning used here for feature engineering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac9579ef"
      },
      "source": [
        "# Logic: Groups data into K clusters; distance to cluster center becomes a feature\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init='auto')\n",
        "X_train_clus = kmeans.fit_transform(x_train)\n",
        "X_test_clus = kmeans.transform(x_test)\n",
        "\n",
        "# Train Logistic Regression on clustered features\n",
        "model = LogisticRegression(random_state=42).fit(X_train_clus, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test_clus)\n",
        "y_pred_proba = model.predict_proba(X_test_clus)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_kmeans_lr = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_kmeans_lr)\n",
        "print(\"Accuracy percent of k-Means Features + LR : \", round(train_score_kmeans_lr*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(X_train_clus, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nk-Means Features + LR Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "kmeans_lr_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nk-Means Features + LR Accuracy@k:\", kmeans_lr_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc158fc1"
      },
      "source": [
        " ### **21. Hierarchical Clustering**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aff6f7d"
      },
      "source": [
        "# Logic: Builds a hierarchy of clusters\n",
        "cluster = AgglomerativeClustering(n_clusters=2)\n",
        "train_cluster_labels = cluster.fit_predict(x_train)\n",
        "\n",
        "# Create pseudo-labels for x_train based on mapped clusters\n",
        "y_train_mapped = np.full_like(y_train, -1, dtype=int)\n",
        "\n",
        "cluster_to_class_map = {}\n",
        "for cluster_id in np.unique(train_cluster_labels):\n",
        "    cluster_indices = np.where(train_cluster_labels == cluster_id)[0]\n",
        "    if len(cluster_indices) > 0:\n",
        "        true_labels_in_cluster = y_train.iloc[cluster_indices]\n",
        "        if not true_labels_in_cluster.empty:\n",
        "            majority_class = np.bincount(true_labels_in_cluster).argmax()\n",
        "            cluster_to_class_map[cluster_id] = majority_class\n",
        "            y_train_mapped[cluster_indices] = majority_class\n",
        "\n",
        "# Train a KNeighborsClassifier as a proxy model\n",
        "proxy_model = KNeighborsClassifier(n_neighbors=5)\n",
        "proxy_model.fit(x_train, y_train_mapped)\n",
        "\n",
        "# Predict on x_test using the proxy classifier\n",
        "y_pred = proxy_model.predict(x_test)\n",
        "y_pred_proba = proxy_model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_hc_proxy = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_hc_proxy)\n",
        "print(\"Accuracy percent of Hierarchical Clustering + kNN Proxy : \", round(train_score_hc_proxy*100, 1), \"%\")\n",
        "print(\"Proxy Model score (on mapped train data): \", proxy_model.score(x_train, y_train_mapped))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nHierarchical Clustering + kNN Proxy Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "hc_proxy_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nHierarchical Clustering + kNN Proxy Accuracy@k:\", hc_proxy_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74cace5f"
      },
      "source": [
        "### **22. DBSCAN**\n",
        "\n",
        "Density-based spatial clustering of applications with noise.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16e3766f"
      },
      "source": [
        "# Logic: Groups dense areas; great for finding outliers (noise)\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5).fit(x_train)\n",
        "\n",
        "# Get cluster labels for training data\n",
        "train_cluster_labels = dbscan.labels_\n",
        "\n",
        "# Create pseudo-labels for x_train based on mapped clusters\n",
        "# Initialize with a placeholder for unmapped/noise points\n",
        "y_train_mapped = np.full_like(y_train, -1, dtype=int)\n",
        "\n",
        "# Majority class of entire y_train, to use for noise points if needed\n",
        "overall_majority_class = np.bincount(y_train).argmax()\n",
        "\n",
        "cluster_to_class_map = {}\n",
        "for cluster_id in np.unique(train_cluster_labels):\n",
        "    if cluster_id == -1:  # Noise points, will be handled later if unmapped\n",
        "        continue\n",
        "\n",
        "    cluster_indices = np.where(train_cluster_labels == cluster_id)[0]\n",
        "    if len(cluster_indices) > 0:\n",
        "        true_labels_in_cluster = y_train.iloc[cluster_indices]\n",
        "        if not true_labels_in_cluster.empty:\n",
        "            majority_class = np.bincount(true_labels_in_cluster).argmax()\n",
        "            cluster_to_class_map[cluster_id] = majority_class\n",
        "            y_train_mapped[cluster_indices] = majority_class  # Assign mapped label\n",
        "\n",
        "# For noise points or unmapped clusters (still -1), assign the overall majority class\n",
        "unmapped_indices = np.where(y_train_mapped == -1)[0]\n",
        "if len(unmapped_indices) > 0:\n",
        "    y_train_mapped[unmapped_indices] = overall_majority_class\n",
        "\n",
        "# Train a KNeighborsClassifier as a proxy model\n",
        "proxy_model = KNeighborsClassifier(n_neighbors=5)\n",
        "proxy_model.fit(x_train, y_train_mapped)\n",
        "\n",
        "# Predict on x_test using the proxy classifier\n",
        "y_pred = proxy_model.predict(x_test)\n",
        "y_pred_proba = proxy_model.predict_proba(x_test)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_dbscan_proxy = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_dbscan_proxy)\n",
        "print(\"Accuracy percent of DBSCAN + kNN Proxy : \", round(train_score_dbscan_proxy*100, 1), \"%\")\n",
        "print(\"Proxy Model score (on mapped train data): \", proxy_model.score(x_train, y_train_mapped))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nDBSCAN + kNN Proxy Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "dbscan_proxy_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nDBSCAN + kNN Proxy Accuracy@k:\", dbscan_proxy_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b4e8a7b"
      },
      "source": [
        "### **23. Principal Component Analysis (PCA)**\n",
        "\n",
        "Used for dimensionality reduction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92dd1a05"
      },
      "source": [
        "# Logic: Projects data onto principal components to reduce noise\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(x_train)\n",
        "X_test_pca = pca.transform(x_test)\n",
        "\n",
        "# Train Logistic Regression on PCA features\n",
        "model = LogisticRegression().fit(X_train_pca, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test_pca)\n",
        "y_pred_proba = model.predict_proba(X_test_pca)[:, 1] # Get probabilities for the positive class\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_pca_lr = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_pca_lr)\n",
        "print(\"Accuracy percent of PCA + LR : \", round(train_score_pca_lr*100, 1), \"%\")\n",
        "print(\"Model score (on train data): \", model.score(X_train_pca, y_train))\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nPCA + Logistic Regression Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "pca_lr_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba, [0.10, 0.20, 0.30])\n",
        "print(\"\\nPCA + Logistic Regression Accuracy@k:\", pca_lr_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e52288c"
      },
      "source": [
        "### **24. Isolation Forest (Anomaly Detection)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fa46c5c"
      },
      "source": [
        "# Logic: Isolates anomalies (minority class) by randomly partitioning features\n",
        "# 'contamination' should match your minority class ratio (e.g., 0.05 for 5%)\n",
        "# Here, we assume the minority class (1 for BUY) is the 'anomaly' detected by Isolation Forest.\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "\n",
        "# Fit on training data (unsupervised)\n",
        "iso_forest.fit(x_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_iso = iso_forest.predict(x_test)\n",
        "\n",
        "# Map Isolation Forest output (-1 for outlier, 1 for inlier) to binary target (1 for BUY, 0 for SELL)\n",
        "# Assuming -1 (outlier) corresponds to the 'BUY' (1) class, and 1 (inlier) to 'SELL' (0) class.\n",
        "y_pred = np.where(y_pred_iso == -1, 1, 0)\n",
        "\n",
        "# Get anomaly scores (lower score = more anomalous = more likely to be positive class)\n",
        "# Negate the scores so that higher values correspond to the positive class for Accuracy@k\n",
        "y_pred_proba_iso = -iso_forest.decision_function(x_test)\n",
        "\n",
        "# Accuracy on test data\n",
        "train_score_iso = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score : ', train_score_iso)\n",
        "print(\"Accuracy percent of Isolation Forest : \", round(train_score_iso*100, 1), \"%\")\n",
        "\n",
        "# Isolation Forest does not have a conventional 'model.score' on train data for classification\n",
        "# We will skip printing model.score(x_train, y_train) for this model due to its unsupervised nature.\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(\"\\nIsolation Forest Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# TN, FP, FN, TP\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN={0}, FP={1}, FN={2}, TP={3}\".format(TN, FP, FN, TP))\n",
        "\n",
        "# Confusion matrix plot\n",
        "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Accuracy@k\n",
        "iso_accuracy_at_k = calculate_accuracy_at_k(y_test, y_pred_proba_iso, [0.10, 0.20, 0.30])\n",
        "print(\"\\nIsolation Forest Accuracy@k:\", iso_accuracy_at_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Table Tabulation**"
      ],
      "metadata": {
        "id": "ZTqUppW8Uj2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy_at_k(y_true, y_pred_proba, k_percentages):\n",
        "    \"\"\"\n",
        "    Calculates Accuracy@k (precision at top k%) for given true labels and predicted probabilities.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): The actual labels (0 or 1).\n",
        "        y_pred_proba (array-like): The predicted probabilities for the positive class.\n",
        "        k_percentages (list): A list of float values representing the top k% thresholds (e.g., [0.10, 0.20, 0.30]).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are 'Accuracy@k%' (e.g., 'Accuracy@10%') and values are the calculated precision percentages.\n",
        "    \"\"\"\n",
        "    # 1. Combine y_true and y_pred_proba into a DataFrame\n",
        "    df_combined = pd.DataFrame({'true_label': y_true, 'predicted_proba': y_pred_proba})\n",
        "\n",
        "    # 2. Sort DataFrame by 'predicted_proba' in descending order\n",
        "    df_combined = df_combined.sort_values(by='predicted_proba', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # 3. Initialize dictionary to store results\n",
        "    accuracy_at_k_results = {}\n",
        "\n",
        "    # 4. Iterate through each k_percentage\n",
        "    for k_percentage in k_percentages:\n",
        "        # a. Calculate the number of samples for the current top k% threshold\n",
        "        k_count = int(len(y_true) * k_percentage)\n",
        "\n",
        "        # Handle the case where k_count is zero (e.g., k_percentage is very small or y_true is empty)\n",
        "        if k_count == 0:\n",
        "            accuracy_at_k_results[f'Accuracy@{int(k_percentage * 100)}%'] = 0.0\n",
        "            continue\n",
        "\n",
        "        # b. Select the top k_count samples from the sorted DataFrame\n",
        "        top_k_df = df_combined.head(k_count)\n",
        "\n",
        "        # c. Within these top k_count samples, count how many have a 'true_label' equal to 1\n",
        "        correct_predictions = top_k_df['true_label'].sum()\n",
        "\n",
        "        # d. Calculate the precision at k\n",
        "        precision_at_k = (correct_predictions / k_count) * 100\n",
        "\n",
        "        # e. Store this calculated precision (percentage) in the results dictionary\n",
        "        accuracy_at_k_results[f'Accuracy@{int(k_percentage * 100)}%'] = precision_at_k\n",
        "\n",
        "    return accuracy_at_k_results\n",
        "\n",
        "print(\"The 'calculate_accuracy_at_k' function has been defined.\")"
      ],
      "metadata": {
        "id": "BpUKZ18Gf65b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c91962dd"
      },
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "data = [\n",
        "    [\"Linear Regression\", round(train_score_lr * 100, 2), round(lr_accuracy_at_k['Accuracy@10%'], 2), round(lr_accuracy_at_k['Accuracy@20%'], 2), round(lr_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"Logistic Regression\", round(train_score_lr * 100, 2), round(logistic_accuracy_at_k['Accuracy@10%'], 2), round(logistic_accuracy_at_k['Accuracy@20%'], 2), round(logistic_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"Na誰ve Bayes\", round(train_score_nb * 100, 2), round(naive_bayes_accuracy_at_k['Accuracy@10%'], 2), round(naive_bayes_accuracy_at_k['Accuracy@20%'], 2), round(naive_bayes_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"LDA\", round(train_score_lda * 100, 2), round(lda_accuracy_at_k['Accuracy@10%'], 2), round(lda_accuracy_at_k['Accuracy@20%'], 2), round(lda_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"SVM\", round(train_score_svm * 100, 2), round(svm_accuracy_at_k['Accuracy@10%'], 2), round(svm_accuracy_at_k['Accuracy@20%'], 2), round(svm_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"k-Nearest Neighbors\", round(train_score_knn * 100, 2), round(knn_accuracy_at_k['Accuracy@10%'], 2), round(knn_accuracy_at_k['Accuracy@20%'], 2), round(knn_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"t-SNE + Logistic Regression\", round(train_score_tsne_lr * 100, 2), round(tsne_lr_accuracy_at_k['Accuracy@10%'], 2), round(tsne_lr_accuracy_at_k['Accuracy@20%'], 2), round(tsne_lr_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"Decision Trees (Cost-Sensitive)\", round(train_score_dt * 100, 2), round(dt_accuracy_at_k['Accuracy@10%'], 2), round(dt_accuracy_at_k['Accuracy@20%'], 2), round(dt_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"Balanced Random Forest\", round(train_score_rand * 100, 2), round(rand_accuracy_at_k['Accuracy@10%'], 2), round(rand_accuracy_at_k['Accuracy@20%'], 2), round(rand_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"Extra Trees\", round(train_score_et * 100, 2), round(et_accuracy_at_k['Accuracy@10%'], 2), round(et_accuracy_at_k['Accuracy@20%'], 2), round(et_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"AdaBoost\", round(train_score_ada * 100, 2), round(ada_accuracy_at_k['Accuracy@10%'], 2), round(ada_accuracy_at_k['Accuracy@20%'], 2), round(ada_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"Gradient Boosting\", round(train_score_gb * 100, 2), round(gb_accuracy_at_k['Accuracy@10%'], 2), round(gb_accuracy_at_k['Accuracy@20%'], 2), round(gb_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"XGBoost\", round(train_score_xgb * 100, 2), round(xgb_accuracy_at_k['Accuracy@10%'], 2), round(xgb_accuracy_at_k['Accuracy@20%'], 2), round(xgb_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"LightGBM\", round(train_score_lgbm * 100, 2), round(lgbm_accuracy_at_k['Accuracy@10%'], 2), round(lgbm_accuracy_at_k['Accuracy@20%'], 2), round(lgbm_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"CatBoost\", round(train_score_cat * 100, 2), round(cat_accuracy_at_k['Accuracy@10%'], 2), round(cat_accuracy_at_k['Accuracy@20%'], 2), round(cat_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"ANN (MLP)\", round(train_score_ann * 100, 2), round(ann_accuracy_at_k['Accuracy@10%'], 2), round(ann_accuracy_at_k['Accuracy@20%'], 2), round(ann_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"CNN\", round(train_score_cnn * 100, 2), round(cnn_accuracy_at_k['Accuracy@10%'], 2), round(cnn_accuracy_at_k['Accuracy@20%'], 2), round(cnn_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"RNN (LSTM)\", round(train_score_lstm * 100, 2), round(lstm_accuracy_at_k['Accuracy@10%'], 2), round(lstm_accuracy_at_k['Accuracy@20%'], 2), round(lstm_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"Autoencoder Features + LR\", round(train_score_ae_lr * 100, 2), round(ae_lr_accuracy_at_k['Accuracy@10%'], 2), round(ae_lr_accuracy_at_k['Accuracy@20%'], 2), round(ae_lr_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"k-Means Features + LR\", round(train_score_kmeans_lr * 100, 2), round(kmeans_lr_accuracy_at_k['Accuracy@10%'], 2), round(kmeans_lr_accuracy_at_k['Accuracy@20%'], 2), round(kmeans_lr_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"Hierarchical Clustering + kNN Proxy\", round(train_score_hc_proxy * 100, 2), round(hc_proxy_accuracy_at_k['Accuracy@10%'], 2), round(hc_proxy_accuracy_at_k['Accuracy@20%'], 2), round(hc_proxy_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"DBSCAN + kNN Proxy\", round(train_score_dbscan_proxy * 100, 2), round(dbscan_proxy_accuracy_at_k['Accuracy@10%'], 2), round(dbscan_proxy_accuracy_at_k['Accuracy@20%'], 2), round(dbscan_proxy_accuracy_at_k['Accuracy@30%'], 2)],\n",
        "    [\"Isolation Forest\", round(train_score_iso * 100, 2), round(iso_accuracy_at_k['Accuracy@10%'], 2), round(iso_accuracy_at_k['Accuracy@20%'], 2), round(iso_accuracy_at_k['Accuracy@30%'], 2)]\n",
        "]\n",
        "\n",
        "columns = [\"Algorithms\", \"Accuracy Percent\", \"Accuracy Percent @10%\", \"Accuracy Percent @20%\", \"Accuracy Percent @30%\"]\n",
        "\n",
        "print(tabulate(data, headers=columns, tablefmt=\"fancy_grid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QYY9gabpbJK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c77b529a"
      },
      "source": [
        "## **Overall Accuracy Percent of Machine Learning Algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e6074c8"
      },
      "source": [
        "# Convert the data list to a DataFrame\n",
        "df_results = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Plot Overall Accuracy Percent\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='Accuracy Percent', y='Algorithms', hue='Algorithms', data=df_results.sort_values(by='Accuracy Percent', ascending=False), palette='viridis', legend=False)\n",
        "plt.title('Overall Accuracy Percent of Machine Learning Algorithms')\n",
        "plt.xlabel('Accuracy Percent (%)')\n",
        "plt.ylabel('Algorithms')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2Do3ChkbT2uI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUA-Jmh2T3Y7"
      },
      "source": [
        "## **Accuracy of Machine Learning Algorithms @ 10%, 20%, 30%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ec55034"
      },
      "source": [
        "# Convert the data list to a DataFrame if not already done\n",
        "df_results = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Melt the DataFrame to prepare for grouped bar plot of Accuracy@k\n",
        "df_accuracy_at_k = df_results[['Algorithms', 'Accuracy Percent @10%', 'Accuracy Percent @20%', 'Accuracy Percent @30%']].melt(\n",
        "    id_vars='Algorithms',\n",
        "    var_name='Accuracy Type',\n",
        "    value_name='Accuracy Value'\n",
        ")\n",
        "\n",
        "# Plot Accuracy@k metrics\n",
        "plt.figure(figsize=(16, 9))\n",
        "sns.barplot(x='Accuracy Value', y='Algorithms', hue='Accuracy Type', data=df_accuracy_at_k, palette='magma')\n",
        "plt.title('Accuracy@k of Machine Learning Algorithms (10%, 20%, 30%)')\n",
        "plt.xlabel('Accuracy Percent (%)')\n",
        "plt.ylabel('Algorithms')\n",
        "plt.legend(title='Accuracy@k Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a06aeaea"
      },
      "source": [
        "## Explanation: Algorithm Selection Rationale\n",
        "\n",
        "### Rationale for Algorithm Selection\n",
        "\n",
        "To conduct a comprehensive comparative analysis for stock price forecasting, a diverse set of machine learning algorithms from various paradigms was selected. This approach allows for evaluating different computational strategies in capturing the complex dynamics of financial time series data.\n",
        "\n",
        "#### 1. Linear & Probabilistic Models (e.g., Linear Regression, Logistic Regression, Na誰ve Bayes, LDA, SVM, k-NN):\n",
        "\n",
        "*   **Characteristics**: These models are generally simpler, provide interpretable results, and establish linear or probabilistic relationships within the data. They are computationally efficient and serve as strong baselines.\n",
        "*   **Relevance for Stock Forecasting**: Despite the non-linear nature of stock markets, linear models can capture fundamental trends and relationships. Logistic Regression and Na誰ve Bayes can classify price movements (e.g., up/down), while LDA seeks to maximize class separability. SVMs can handle non-linearity through kernels, and k-NN classifies based on local proximity, useful for identifying similar market conditions.\n",
        "\n",
        "#### 2. Tree-Based & Ensemble Learning Models (e.g., Decision Trees, Random Forest, Extra Trees, AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost):\n",
        "\n",
        "*   **Characteristics**: These models excel at capturing non-linear relationships and interactions between features. Ensemble methods combine multiple individual models to improve predictive performance and robustness, often reducing overfitting and bias. They are particularly effective with complex, high-dimensional data.\n",
        "*   **Relevance for Stock Forecasting**: Stock prices are influenced by numerous interdependent factors, making them highly non-linear. Tree-based ensembles are well-suited for such complexity, capable of identifying intricate patterns that drive price movements. Boosting algorithms (AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost) sequentially improve predictions by focusing on previous errors, which is critical in time-series forecasting where subtle shifts can be significant.\n",
        "\n",
        "#### 3. Neural Networks & Deep Learning Models (e.g., ANN/MLP, CNN, RNN/LSTM, Autoencoders):\n",
        "\n",
        "*   **Characteristics**: Deep learning models, with their multi-layered architectures, can automatically learn hierarchical features and complex abstractions directly from raw data. RNNs and LSTMs are particularly adept at processing sequential data, making them suitable for time series. Autoencoders can learn efficient data encodings.\n",
        "*   **Relevance for Stock Forecasting**: Stock prices are inherently sequential and exhibit temporal dependencies. RNNs and LSTMs are designed to handle such sequences, making them powerful tools for predicting future price movements based on historical patterns. ANNs/MLPs offer general non-linear mapping capabilities, while CNNs can identify local patterns within data windows. Autoencoders can be used for dimensionality reduction and feature learning, potentially extracting more robust signals from noisy financial data.\n",
        "\n",
        "#### 4. Clustering & Unsupervised Models (e.g., k-Means Clustering, Hierarchical Clustering, DBSCAN, PCA, Isolation Forest):\n",
        "\n",
        "*   **Characteristics**: These models operate without labeled data, identifying inherent structures, groups, or anomalies within the dataset. They are valuable for exploratory data analysis, feature engineering, and anomaly detection.\n",
        "*   **Relevance for Stock Forecasting**: While primarily unsupervised, these techniques can enhance supervised forecasting models. Clustering algorithms (k-Means, Hierarchical, DBSCAN) can identify different market regimes or stock behavior patterns, which can then be used as features. Dimensionality reduction techniques like PCA can reduce noise and multicollinearity, improving model stability. Isolation Forest, an anomaly detection algorithm, can be used to identify unusual market events or outliers, which might correspond to significant price shifts or unusual trading activity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14e3c185"
      },
      "source": [
        "## Explanation: Hyperparameter Tuning Strategy\n",
        "\n",
        "For the purpose of this comparative analysis, all machine learning models were trained using their default hyperparameters, as provided by their respective libraries (e.g., scikit-learn, TensorFlow, XGBoost, LightGBM, CatBoost). While this approach allows for a direct comparison of models under their standard configurations, it's crucial to acknowledge that it does not represent the optimal performance achievable by each model.\n",
        "\n",
        "**Importance of Hyperparameter Tuning:**\n",
        "\n",
        "Hyperparameter tuning is a critical step in the machine learning workflow, especially for complex tasks like stock price forecasting where minor improvements in prediction accuracy can have significant financial implications. Manually setting hyperparameters or relying on defaults can lead to suboptimal model performance, including issues such as overfitting, underfitting, or simply not capturing the underlying patterns in the data effectively.\n",
        "\n",
        "**Common Hyperparameter Tuning Techniques:**\n",
        "\n",
        "Techniques such as Grid Search, Random Search, Bayesian Optimization, and evolutionary algorithms are commonly employed to systematically explore the hyperparameter space and identify the combination that yields the best performance on a validation set. By tuning parameters like `n_estimators`, `learning_rate`, `max_depth`, `C`, `gamma`, `hidden_layer_sizes`, etc., models can be significantly optimized for the specific dataset and problem at hand.\n",
        "\n",
        "**Future Work:**\n",
        "\n",
        "To further enhance the predictive accuracy and robustness of the models for stock price forecasting, future work should explicitly incorporate comprehensive hyperparameter tuning for each model. This would involve:\n",
        "\n",
        "1.  **Defining a search space** for each model's key hyperparameters.\n",
        "2.  **Employing a cross-validation strategy** to ensure robust evaluation of different hyperparameter combinations.\n",
        "3.  **Using appropriate evaluation metrics** (e.g., RMSE, MAE, MAPE, R族, Accuracy@k for classification) to guide the optimization process.\n",
        "\n",
        "Implementing such tuning would likely lead to improved model performance, making them more suitable for real-world financial applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5913451d"
      },
      "source": [
        "## Explanation: Training-Validation-Testing Split and Cross-Validation\n",
        "\n",
        "### Data Splitting Strategy\n",
        "\n",
        "For this analysis, a `train_test_split` with `shuffle=False` was employed to divide the dataset into training and testing sets. This approach is crucial when dealing with time-series data, as maintaining the temporal order of observations is essential. Shuffling would disrupt the chronological sequence, leading to data leakage where future information could inadvertently influence the training of models, thereby yielding misleading performance metrics.\n",
        "\n",
        "### Absence of Explicit Cross-Validation\n",
        "\n",
        "Standard k-fold cross-validation, where data is randomly partitioned into subsets, is generally not suitable for time-series forecasting. The primary reason is that it violates the temporal dependency inherent in such data. Randomly splitting the data would lead to training on future observations and testing on past ones, which does not reflect real-world forecasting scenarios.\n",
        "\n",
        "While explicit cross-validation was not performed in this notebook, its absence implies that the model's robustness and generalization to different time periods might not be as thoroughly assessed as with more appropriate time-series cross-validation techniques. These specialized techniques, such as **rolling-origin cross-validation** (also known as forward-chaining cross-validation) or **blocked cross-validation**, preserve the temporal order by iteratively training on a growing past segment of data and testing on a subsequent future segment.\n",
        "\n",
        "For more rigorous evaluation of time-series models, implementing one of these time-series specific cross-validation methods would be recommended to ensure that the model's performance is consistently robust across various future periods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32482a48"
      },
      "source": [
        "## **Results and Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "854bbda5"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## **Tabular and Graphical Presentation of Results**\n",
        "\n",
        "The previous output provides a comprehensive table detailing the performance of each machine learning model across various metrics, including overall Accuracy Percent and Accuracy@k at different thresholds (10%, 20%, and 30%). This tabular format offers a direct quantitative comparison of how each model performs in identifying positive cases within the top predicted percentages.\n",
        "\n",
        "To further enhance our understanding and visualize these comparisons more effectively, we will now proceed to create graphical representations of these results. The graphical comparison will specifically focus on:\n",
        "\n",
        "- **Overall Accuracy Percent**: To visualize the general predictive power of each model.\n",
        "- **Accuracy@10%, Accuracy@20%, and Accuracy@30%**: To highlight the models' effectiveness in identifying the most confident positive predictions, which is crucial for applications where focusing on a small, high-precision subset is valuable.\n",
        "\n",
        "These visual summaries will offer a clear and intuitive way to compare the models' strengths and weaknesses across different evaluation criteria, complementing the detailed quantitative insights provided by the table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4f0b13f"
      },
      "source": [
        "## **Performance Comparison and Interpretation**\n",
        "\n",
        "This section provides a comparative analysis of the eighteen machine learning models evaluated for stock price forecasting, focusing on their 'Accuracy Percent' and 'Accuracy@k' scores.\n",
        "\n",
        "### Overall Accuracy Assessment\n",
        "\n",
        "The 'Accuracy Percent' column represents the overall proportion of correctly classified instances on the test set. Higher values generally indicate better predictive capability for the entire dataset. From the tabulated results:\n",
        "\n",
        "*   **Extra Trees (72.47%)**, **Balanced Random Forest (71.35%)**, and **XGBoost (71.35%)** demonstrate the highest overall accuracy. These ensemble methods, particularly tree-based ones, appear to capture the underlying patterns in the data more effectively than other models.\n",
        "*   **Gradient Boosting (70.79%)** and **CatBoost (69.66%)** also perform strongly, reinforcing the robustness of gradient-boosting techniques.\n",
        "*   **k-Nearest Neighbors (68.54%)** shows competitive performance, suggesting that local data structures are relevant for classification.\n",
        "*   **Linear and Probabilistic models** like Linear Regression (53.37%), Logistic Regression (53.37%), Na誰ve Bayes (43.82%), and LDA (47.19%) generally exhibit lower overall accuracy, indicating the potential for non-linear relationships in the data that these models might struggle to capture.\n",
        "*   **Neural Networks**, including ANN (MLP) (66.85%), CNN (61.24%), and RNN (LSTM) (64.04%), show moderate performance, with ANN being the strongest among them. Their performance could potentially be improved with more complex architectures or extensive hyperparameter tuning.\n",
        "*   **Unsupervised feature extraction methods**, when combined with Logistic Regression (Autoencoder Features + LR: 51.12%, k-Means Features + LR: 51.12%, PCA + Logistic Regression: 50.00%), show lower accuracy. This suggests that the features extracted might not be optimally discriminative for the classification task, or that the linear classifier on top is insufficient.\n",
        "*   **Clustering-based proxy models** like Hierarchical Clustering + kNN Proxy (38.20%) and DBSCAN + kNN Proxy (38.76%), along with **Isolation Forest (57.30%)**, exhibit the lowest accuracies. This indicates that these methods, designed for different tasks (density/anomaly detection, unsupervised grouping), are less suited for direct supervised classification without significant adaptations or more sophisticated integration.\n",
        "\n",
        "### Accuracy@k Interpretation\n",
        "\n",
        "'Accuracy@k' (Precision@k) is a crucial metric, especially in scenarios like stock prediction where identifying a small subset of high-confidence predictions is more valuable than overall accuracy. It measures the percentage of correct positive predictions among the top k% of instances with the highest predicted probabilities for the positive class. This metric is critical for strategies that act on a limited number of high-conviction signals.\n",
        "\n",
        "*   **Top 10% (Accuracy@10%)**: Here, **t-SNE + Logistic Regression (76.47%)**, **AdaBoost (76.47%)**, and **PCA + Logistic Regression (76.47%)** perform exceptionally well. While their overall accuracies might not be the highest, they are very effective at identifying a small, highly probable subset of 'BUY' signals. This suggests that while these models may not generalize well across all predictions, they can be highly precise when focusing on the most confident predictions.\n",
        "*   **Top 20% (Accuracy@20%)**: **XGBoost (71.43%)** and **Autoencoder Features + LR (71.43%)** lead in this category. This indicates that their confidence scores are well-calibrated for selecting a slightly larger portion of the dataset, providing reliable signals at this threshold.\n",
        "*   **Top 30% (Accuracy@30%)**: **Balanced Random Forest (67.92%)**, **Extra Trees (67.92%)**, and **CatBoost (67.92%)** perform best here. These models maintain strong precision even when considering a larger fraction of the top predictions, highlighting their ability to consistently rank positive instances higher.\n",
        "\n",
        "**Empirical Observations and Trade-offs:**\n",
        "\n",
        "It's evident that models with high overall accuracy (like Extra Trees or Balanced Random Forest) generally perform well across Accuracy@k metrics, but some models, like t-SNE + LR, AdaBoost, and PCA + LR, show a significant boost in Accuracy@10% despite having moderate overall accuracy. This implies a trade-off: a model might have lower overall accuracy but be excellent at identifying a small, critical subset of highly probable positive outcomes, which is often more desirable in financial applications (e.g., maximizing returns by only acting on the strongest buy signals).\n",
        "\n",
        "Conversely, models with very low overall accuracy (e.g., Hierarchical Clustering, DBSCAN) also show poor Accuracy@k scores, confirming their limited utility for this particular classification task.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "For a balanced performance considering both overall predictive power and the ability to identify high-confidence predictions, **tree-based ensemble models (Extra Trees, Balanced Random Forest, XGBoost, CatBoost, Gradient Boosting)** stand out as the most robust choices. However, for strategies prioritizing high precision on a very small set of top predictions, **t-SNE + Logistic Regression, AdaBoost, and PCA + Logistic Regression** present compelling alternatives, suggesting that dimensionality reduction or boosting can enhance the confidence of predictions for the most salient cases. The choice of the"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13368968"
      },
      "source": [
        "## **Strengths, Weaknesses, and Trade-offs**\n",
        "\n",
        "### Linear & Probabilistic Models (Linear Regression, Logistic Regression, Na誰ve Bayes, LDA, SVM, k-NN):\n",
        "\n",
        "**Strengths:**\n",
        "- **Interpretability:** Generally highly interpretable, especially Linear and Logistic Regression, making it easier to understand feature importance.\n",
        "- **Simplicity:** Simpler to implement and faster to train, particularly for smaller datasets.\n",
        "- **Scalability:** Can scale well to large datasets, with some models (like Linear/Logistic Regression) having efficient implementations.\n",
        "- **Robustness (SVM):** SVMs can be effective in high-dimensional spaces and with clear margins.\n",
        "\n",
        "**Weaknesses:**\n",
        "- **Limited to Linear Relationships:** Linear Regression and Logistic Regression struggle with non-linear relationships in data.\n",
        "- **Assumption Dependent (Na誰ve Bayes, LDA):** Na誰ve Bayes assumes feature independence, which is rarely true in practice. LDA assumes Gaussian distributions and equal covariance matrices.\n",
        "- **Sensitivity to Outliers:** Many linear models are sensitive to outliers.\n",
        "- **Performance (k-NN):** Can be computationally expensive for prediction on large datasets due to distance calculations.\n",
        "\n",
        "**Trade-offs:** High interpretability and faster training often come at the cost of lower predictive power on complex, non-linear data compared to ensemble or deep learning methods.\n",
        "\n",
        "### Tree-Based Ensembles (Decision Trees, Balanced Random Forest, Extra Trees, AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost):\n",
        "\n",
        "**Strengths:**\n",
        "- **High Accuracy:** Often achieve state-of-the-art performance, especially Gradient Boosting machines, due to their ability to capture complex non-linear relationships.\n",
        "- **Feature Importance:** Provide clear insights into feature importance.\n",
        "- **Handles Mixed Data Types:** Can naturally handle both numerical and categorical features.\n",
        "- **Robust to Outliers (some):** Ensemble methods like Random Forests are less sensitive to outliers than single decision trees.\n",
        "- **Scalability:** Many modern implementations (XGBoost, LightGBM, CatBoost) are highly optimized for speed and scalability.\n",
        "\n",
        "**Weaknesses:**\n",
        "- **Overfitting (Decision Trees):** Single Decision Trees are prone to overfitting without proper pruning.\n",
        "- **Complexity:** Ensembles can be complex, making them less interpretable than linear models.\n",
        "- **Parameter Tuning:** Often require careful hyperparameter tuning for optimal performance.\n",
        "- **Computational Cost:** Can be computationally intensive to train, especially for large ensembles or deep trees.\n",
        "\n",
        "**Trade-offs:** Excellent predictive power and robustness are achieved at the cost of increased complexity and reduced interpretability compared to linear models. Training times can be longer.\n",
        "\n",
        "### Neural Networks & Deep Learning (ANN/MLP, CNN, RNN/LSTM, Autoencoders):\n",
        "\n",
        "**Strengths:**\n",
        "- **Captures Complex Patterns:** Exceptional at learning intricate patterns and representations from data, leading to high accuracy, especially on large, complex datasets.\n",
        "- **Feature Learning:** Can automatically learn relevant features from raw data, reducing the need for manual feature engineering.\n",
        "- **Versatility:** Applicable to various data types (sequences, images, text) and tasks.\n",
        "\n",
        "**Weaknesses:**\n",
        "- **Data Hungry:** Require very large datasets to perform optimally and avoid overfitting.\n",
        "- **Computational Expense:** Extremely resource-intensive to train, requiring significant computational power (GPUs/TPUs).\n",
        "- **Black Box:** Very difficult to interpret, often considered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01afdeb9"
      },
      "source": [
        "## **Data Analysis Key Findings**\n",
        "\n",
        "*   **Algorithm Selection Rationale**: A diverse set of machine learning algorithms was chosen to comprehensively compare performance in stock price forecasting.\n",
        "    *   **Linear & Probabilistic Models** were selected as interpretable baselines to capture fundamental trends.\n",
        "    *   **Tree-Based & Ensemble Learning Models** were included for their ability to handle non-linear relationships and improve robustness.\n",
        "    *   **Neural Networks & Deep Learning Models** were chosen for their capability to learn hierarchical features and process sequential data, crucial for time series.\n",
        "    *   **Clustering & Unsupervised Models** were selected for identifying inherent structures, reducing dimensionality, and detecting anomalies, thereby enhancing supervised models.\n",
        "*   **Hyperparameter Tuning Strategy**: All models were trained using their default hyperparameters. This approach allowed for a direct comparison under standard configurations but implied that optimal performance for each model might not have been achieved. The importance of hyperparameter tuning for optimization and robustness was emphasized, with suggestions for future work involving defining search spaces, cross-validation, and appropriate evaluation metrics.\n",
        "*   **Data Splitting Strategy**: A `train_test_split` with `shuffle=False` was used to maintain the temporal order of time-series data, preventing data leakage. Standard k-fold cross-validation was noted as unsuitable for time series, and the absence of explicit time-series specific cross-validation (like rolling-origin) was acknowledged, suggesting it as an area for more rigorous future evaluation.\n",
        "*   **Performance Comparison and Interpretation**:\n",
        "    *   **Overall Accuracy**: Tree-based ensemble models consistently showed the highest overall accuracy, with **Extra Trees (72.47%)**, **Balanced Random Forest (71.35%)**, and **XGBoost (71.35%)** leading. Linear and probabilistic models, along with unsupervised feature extraction/clustering-based proxy models, generally exhibited lower overall accuracies. Neural networks showed moderate performance.\n",
        "    *   **Accuracy@k (Precision@k)**: This metric, crucial for high-conviction signals, revealed different leaders for specific thresholds.\n",
        "        *   For **Accuracy@10%**, **t-SNE + Logistic Regression (76.47%)**, **AdaBoost (76.47%)**, and **PCA + Logistic Regression (76.47%)** performed exceptionally well, indicating their ability to precisely identify a small subset of high-probability positive predictions despite potentially lower overall accuracy.\n",
        "        *   For **Accuracy@20%**, **XGBoost (71.43%)** and **Autoencoder Features + LR (71.43%)** were top performers.\n",
        "        *   For **Accuracy@30%**, **Balanced Random Forest (67.92%)**, **Extra Trees (67.92%)**, and **CatBoost (67.92%)** maintained strong precision.\n",
        "    *   A trade-off was observed where models with lower overall accuracy could still be highly effective at identifying a small, precise set of predictions, which is valuable in financial applications.\n",
        "*   **Strengths, Weaknesses, and Trade-offs of Model Categories**:\n",
        "    *   **Linear & Probabilistic Models**: High interpretability and simplicity at the cost of limited ability to capture non-linear relationships.\n",
        "    *   **Tree-Based Ensembles**: High accuracy and robustness for complex non-linear data, but with increased complexity, need for tuning, and reduced interpretability compared to linear models.\n",
        "    *   **Neural Networks & Deep Learning**: Highest potential for accuracy on complex data with automatic feature learning, but are data-hungry, computationally expensive, and lack interpretability (\"black box\").\n",
        "    *   **Clustering & Unsupervised Models**: Excellent for pattern discovery, dimensionality reduction, and anomaly detection, primarily used to enhance supervised models rather than for direct prediction.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   To fully optimize model performance, comprehensive hyperparameter tuning and time-series specific cross-validation (e.g., rolling-origin) should be implemented in future work to ensure robustness and generalizability of the models.\n",
        "*   The choice of the \"best\" model depends on the specific financial strategy: if maximizing overall correct predictions is key, tree-based ensembles are preferred; if high precision on a small set of high-confidence signals is critical, models like AdaBoost or dimensionality reduction combined with linear models (e.g., t-SNE + LR) show promise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Answering the Aim and Objectives of the Study**"
      ],
      "metadata": {
        "id": "yOxXMnmXODxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**General Objective:**\n",
        "**To conduct a comprehensive comparative analysis of eighteen machine learning models for stock price forecasting in the financial sector using historical Yahoo Finance data.**\n",
        "\n",
        "**Interpretation:** This objective was successfully met by evaluating eighteen diverse machine learning models across different paradigms (linear, tree-based, neural networks, and unsupervised techniques used for feature engineering). The study provided a detailed comparison of their performance using 'Accuracy Percent' and 'Accuracy@k' metrics, alongside discussions on their strengths, weaknesses, and trade-offs.\n",
        "\n",
        "**Specific Objectives:**\n",
        "\n",
        "1.  **Examine the predictive performance of traditional regression-based machine learning models in forecasting stock prices.**\n",
        "    *   **Interpretation:** Traditional regression-based models like Linear Regression (53.37% accuracy), Logistic Regression (53.37% accuracy), and LDA (47.19% accuracy) generally showed lower overall predictive performance compared to ensemble methods. While some, when combined with dimensionality reduction (e.g., PCA + LR), achieved high 'Accuracy@10%', their overall ability to capture complex stock price dynamics was limited, suggesting that the problem is highly non-linear.\n",
        "\n",
        "2.  **Evaluate the effectiveness of tree-based and ensemble learning models for financial time-series prediction.**\n",
        "    *   **Interpretation:** Tree-based and ensemble learning models (Extra Trees, Balanced Random Forest, XGBoost, Gradient Boosting, CatBoost, AdaBoost) demonstrated superior effectiveness, consistently achieving the highest overall accuracy scores (ranging from 67.42% to 72.47%). They proved robust in capturing non-linear relationships and interactions within the financial data, making them highly suitable for stock price forecasting. Their strong performance across various Accuracy@k thresholds further validates their utility in identifying high-conviction signals.\n",
        "\n",
        "3.  **Assess the capability of kernel-based and probabilistic models in capturing non-linear stock price dynamics.**\n",
        "    *   **Interpretation:** Kernel-based models like SVM (57.87% accuracy) showed moderate capability, improving upon purely linear models by handling some non-linearity through its kernel trick. Probabilistic models like Na誰ve Bayes (43.82% accuracy) performed poorly, likely due to its strong assumption of feature independence which is often violated in financial data. This suggests that while kernel methods can help, simpler probabilistic approaches may not be sophisticated enough for complex non-linear dynamics.\n",
        "\n",
        "4.  **Analyze the forecasting accuracy of deep learning models in comparison with conventional machine learning techniques.**\n",
        "    *   **Interpretation:** Deep learning models (ANN/MLP: 66.85%, CNN: 61.24%, RNN/LSTM: 64.04%) showed competitive but generally not superior accuracy compared to the top ensemble models. While they captured complex patterns, their performance on this dataset with limited features and default hyperparameters did not overwhelmingly outperform the best conventional techniques. This indicates that their full potential might be realized with more data, extensive feature engineering, or dedicated hyperparameter tuning and architecture optimization.\n",
        "\n",
        "5. **Identify the most robust and generalizable machine learning models for stock price forecasting using historical market data**\n",
        "    * **Interpretation** Based on the notebook's accuracy and Accuracy@k results, the **tree-based ensemble models** are the most robust and generalizable for this classification task. Specifically, **Extra Trees (72.47% overall accuracy)**, **Balanced Random Forest (71.35% overall accuracy)**, **XGBoost (71.35% overall accuracy)**, **Gradient Boosting (70.79% overall accuracy)**, and **CatBoost (69.66% overall accuracy)** consistently demonstrate strong performance across both overall accuracy and the various Accuracy@k thresholds. These models are effective at capturing complex, non-linear relationships in the data and offer a good balance between overall predictive power and the ability to identify high-confidence predictions, making them well-suited for general application in this classification scenario.\n",
        "\n"
      ],
      "metadata": {
        "id": "KobWAG7mONSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Assuming y_test and y_pred are available from the last classification model\n",
        "# Note: Applying regression metrics to binary classification outcomes provides insight\n",
        "# into how 'close' the binary predictions are, but does not directly evaluate continuous forecasting performance.\n",
        "\n",
        "# Mean Squared Error (MSE)\n",
        "mse = metrics.mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "\n",
        "# R-squared (Coefficient of Determination)\n",
        "# Note: R-squared can be misleading or negative for classification problems with binary outputs\n",
        "# as it's designed for continuous targets. A low or negative value is expected here.\n",
        "r2 = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R-squared (R2): {r2:.4f}\")"
      ],
      "metadata": {
        "id": "H9zJbX3_WhA2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}